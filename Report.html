<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta, title, CSS, favicons, etc. -->
        <meta charset="utf-8">
    <title>CS 491: Assignment 4 writeup by Pratibha</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Course CS 491 UIC writeup">

    <link href="/datascience/css/bootstrap.css" rel="stylesheet">
    <link href="/datascience/css/site.css" rel="stylesheet">
    <link href="/datascience/css/github.css" rel="stylesheet">
    <link href='https://fonts.googleapis.com/css?family=Droid+Sans:400,700' rel='stylesheet' type='text/css'>


    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></sc\
ript>
    <![endif]-->
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-21532225-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
    
    
    <!-- Place anything custom after this. -->
  </head>
  <body>
    

        <div class="col-md-9" role="main">
          <h1 id="assignment-4" style="color:blue;">Assignment 4 Writeup by Pratibha </h1>
          
    <h2 style="color:blue;">Introduction</h2>
    <p> Twitter is an online micro-blogging and social-networking platform which allows
users to write short status updates of maximum length 140 characters. It is a rapidly
expanding service with over 200 million registered users out of which 100
million are active users and half of them log on twitter on a daily basis - generating
nearly 250 million tweets per day . Due to this huge amount of users we can
achieve a reflection of public sentiment by analysing the sentiments expressed in the
form of tweets. Analysing the public sentiment is important for many applications such as
firms trying to find out the feedback of their products in the market, predicting political
elections and predicting socioeconomic phenomena like stock exchange. The aim of
this assignment is to use Apache Spark's MLlib classifiers to determine the sentiment of a given tweet.</p>


<h2 style="color:blue;">Problem Statement</h2>
<p>The problem statement is , given a message, classify whether the message is of positive (1), negative (0) sentiment by using Apache Spark's mllib Naive Bayes classifier, Logistic Regression classifer and
Decision tree classifer.</p>


<h2 style="color:blue;"> Domain Introduction</h2>
<p>Analyzing tweet sentiments comes under the domain of
“Pattern Classification” and “Data Mining”. The process of finding "useful" patters can be done using Supervised or Unsupervised learning methods.
In supervised learning, the output datasets are provided which are used to train the machine
 and get the desired outputs whereas in unsupervised learning no datasets are provided, instead the data is clustered into different classes
.Here , we are making use of “Machine Learning” techniques  such as Naive Bayes, Logistic Regression, and Decision Tree for accurately classifying
 the given test data according to whichever pattern model best
describes them.</p>


<h2 style="color:blue;">The Apache Spark Setup</h2>
<li> Install Apache Spark 1.6.1  </li>
<li> Install nltk for the purpose of Porterstemmer </li>
<li> Install jupyter notebook</li>
<li> Connect your VM to jupyter notebook using secure shell</li>
<li> Resolve dependencies as and when errors are thrown, like numpy </li>
<li> Install matplotlib libraries for the graphs to be plotted</li>

<hr />
<h3 id="Q1" style="color:blue;">1. Tweet processing steps</h3>


  <p>Tweet text formatting techniques are :</p>
  <p>2)Import the necessary libraries which are required for reading the tweets,cleaning the tweets like nltk, regular expressions and the spark’s mllib which are required for tweet classification.</p>
  <p>3)Load the training and testing dataset as an RDD using SparkContext object sc.</p>
  <p>4)Parse each tweet by converting to lowercase and do the following processing steps which are defined in cleantweets() function.</p>
  <ul>
  <li>       Replace a word containing ‘http’/’https’ with URL using regular expressions as we are interested in analyzing the tweet text only.</li>
  <li>       Replace a word containing  ‘www.’ with URL using regular expressions as we are interested in analyzing the tweet text only.</li>
  <li>       Replace a word containing ‘@’ with AT_USER as we are interested in analyzing the tweet text only.</li>
  <li>       Tokenization/Lexical analysis is the process of breaking a stream of text  into words, symbols and other meaningful elements called “tokens”. 
  Tokens can be separated by whitespace characters and/or punctuation characters. The list of tokens becomes input for further processing such as parsing or text mining.</li>
  <li>      For each token in a tweet do the below processing steps:</li>
  <ol type='a'>
  <li>              Stemming - It is the process of normalizing a text by reducing a derived word to its root or stem. For example a stemmer would reduce the phrases “feeling”, 
  “feels” to the root word “feel”.This process makes the comparison between words simpler, as we do not need to deal with complex grammatical transformations of the word. 
  Here, we are using nltk’s Porterstemmer to perform stemming.</li>
  <li>              Further Formatting </li>
  </ol>
  <li>                    Replace #token with token .</li>
  <li>                    Ignore words which does not start with alphabets using isalpha() function.</li>
  <li>Check for any stopwords like ‘a’,’an’,’me’,’the’ in the stopwords list and remove them as they do not provide any valuable information.</li>
  <li> Remove all the punctuations from the tokens as they do not provide any valuable information.</li>
  <li> Replace all multiple occurrences(more than 2) of characters to just 2.</li>
  </ul>
  <p>Finally, the output of the function is the clean tweet which can be further considered for analysis.</p>
  



<hr />
<h3 id="Q1" style="color:blue;">2. Feature space</h3>
<p> HashingTF is a Transformer which takes sets of terms and converts those sets into fixed-length feature vectors. It transforms a bag of words into a vector
 of term frequencies by applying a hash function to each term.Unigrams are considered here.The size of the feature space is 50,000 to lessen the chances of collisions,
 because the vector has a finite number of elements, it's possible that two terms will map to the same hashed term.</p>
 <hr />
 
<h3 id="Q1" style="color:blue;">3. Parameter tuning on three classifiers: NB, LOG and DT</h3>
<p> For the Decision tree classifier, we have reduced the number of features by trial and error method as a large value would run forever and the notebook timed out. </p>
<hr />

<h3 id="Q1" style="color:blue;">4. Performance Metrics</h3>
<p style="color:blue;"><u>NB Classifier values </u></p>
<p>Naive-Bayes classifier train-train accuracy - 81.3175 </p>
<p>10-fold cross-validation accuracy values are </p>
<table border="1" style="width:600px">
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td> 75.0285207250602</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td> 73.97106510351709</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>75.05233345647088</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>75.22471198885935</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td> 73.80715705765407</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td> 74.51632778804684</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>75.36597677940435</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>74.80867346938776</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>74.73111633081963</td>
</tr>
<tr>
<td>Naive-Bayes classifier K-fold accuracy</td>
<td>74.76728310785651</td>
</tr>
<tr>
<td>Naive-Bayes classifier average for K-fold classifier</td>
<td>74.72731658070767</td>
</tr>
</table>
<p>Naive-Bayes Test accuracy - 79.38718662952647</p>
<p>Performance metrics for Naive-Bayes</p>
<li>Precision : 0.7934782608695652</li>
<li>Recall : 0.8021978021978022</li>
<li>f1-measure: 0.7978142076502732</li>
<li>Area under ROC: 0.7937542683305395</li>
​
<p style="color:blue;"><u>LOR Classifier values</u> </p>
<p>Logistic Regression train-train classifier - 87.36 </p>
<p>10-fold cross-validation accuracy values are </p>
<table border="1" style="width:600px">
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td> 71.88322265380278</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td>72.70918811388786</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td>71.555336455509</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td>71.33199799699548</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td> 71.59815069348994</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td>71.11616736190115</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td> 72.08569628229363</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td> 71.74314183786443</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td> 72.44084524863976</td>
</tr>
<tr>
<td>Logistic Regression classifier K-fold accuracy</td>
<td>71.78781433754536</td>
</tr>
<tr>
<td>Logistic Regression classifier average for K-fold classifier</td>
<td> 71.82515609819293</td>
</tr>
</table>
<p>Logistic_Regression Test accuracy - 77.99442896935933</p>
<p>Performance metrics for Logistic Regression</p>
<li>Precision : 0.7754010695187166</li>
<li>Recall : 0.7967032967032966</li>
<li>f1-measure: 0.7859078590785907</li>
<li>Area under ROC: 0.7797075805550382</li> 

<p style="color:blue;"><u>DT Classifier values</u> </p>
<p>Decision tree train-train classifier - 62.21875 </p>
<p>10-fold cross-validation accuracy values are </p>
<table border="1" style="width:600px">
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td> 62.077173640691555</td>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>62.432915921288014</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>61.7165019391968</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td> 62.03406566279931</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>61.32855908136807</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td> 61.8779694923731</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td> 62.189980158730165</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>62.116545521744484</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>63.00227445034117</td>
</tr>
<tr>
<td>Decision tree classifier K-fold accuracy</td>
<td>62.51739405439595</td>
</tr>
<tr>
<td>Decision tree Regression classifier average for K-fold classifier</td>
<td>62.129337992292854</td>
</tr>
</table>
<p>Decision tree Test accuracy - 60.16713091922006</p>
<p>Performance metrics for Logistic Regression</p>
<li>Precision : 0.510989010989011</li>
<li>Recall : 0.6326530612244898</li>
<li>f1-measure: 0.5653495440729484</li>
<li>Area under ROC: 0.6064208702348864</li> 

<br/>

<li style="color:blue;"><u>Findings</u></li>
<br/>
<table border="1" style="width:600px">
<tr>
<td>Classifier</td>
<td>Naive-Bayes</td>
<td>Logistic_Regression</td>
<td>decision-tree</td>
</tr>
<tr>
<td>Training Accuracy</td>
<td>81.3175</td>
<td>87.36 </td>
<td>62.21875</td>
</tr>
<tr>
<td>10-fold cross validation Accuracy</td>
<td>74.72731658070767</td>
<td>71.82515609819293</td>
<td>62.129337992292854</td>
</tr>
<tr>
<td>Test Accuracy</td>
<td>79.38718662952647</td>
<td>77.99442896935933</td>
<td>60.16713091922006</td>
</tr>
<tr>
<td>Precision</td>
<td>0.7934782608695652</td>
<td>0.7754010695187166</td>
<td>0.510989010989011</td>
</tr>
<tr>
<td>Recall</td>
<td>0.8021978021978022</td>
<td>0.7967032967032966</td>
<td>0.6326530612244898</td>
</tr>
<tr>
<td>F1 measure</td>
<td>0.7978142076502732</td>
<td>0.7859078590785907</td>
<td>0.5653495440729484</td>
</tr>
</table>
<br />

<p> From the above comparison table, we can say that when the test is done on the data on which it is trained, logistic-regression performs really well with accuracy about 87% , 
but when it is tested using test data which is different from train data, which can be seen from Test Accuracy and 10-fold cross-validation Accuracy, Naive-Bayes classifer performs 
well when compared to Logistic-Regression and Decision-tree. </p>




<table border="1" style="width:300px">
<tr>
<td>General Confusion Matrix </td>
<td>Prediction says Yes</td>
<td>Prediction says No</td>
</tr>
<tr>
<td>Observation says Yes</td>
<td>True positive</td>
<td>False negative</td>
</tr>
<tr>
<td>Observation says No</td>
<td>False positive</td>
<td>True negative</td>
</tr>
</table>
<br />
<table border="1" style="width:300px">
<tr>
<td>Confusion Matrix for Naive_Bayes_classifier </td>
<td>Prediction says Yes</td>
<td>Prediction says No</td>
</tr>
<tr>
<td>Observation says Yes</td>
<td>146</td>
<td>36</td>
</tr>
<tr>
<td>Observation says No</td>
<td>38</td>
<td>139</td>
</tr>
</table>

<br />

<table border="1" style="width:300px">
<tr>
<td>Confusion Matrix for logistic-regression classifer </td>
<td>Prediction says Positive</td>
<td>Prediction says Negative</td>
</tr>
<tr>
<td>Observation says Positive</td>
<td>145</td>
<td>37</td>
</tr>
<tr>
<td>Observation says Negative</td>
<td>42</td>
<td>135</td>
</tr>
</table>
<br />
<table border="1" style="width:300px">
<tr>
<td>Confusion Matrix for decision-tree classifer </td>
<td>Prediction says Positive</td>
<td>Prediction says Negative</td>
</tr>
<tr>
<td>Observation says Positive</td>
<td>93</td>
<td>54</td>
</tr>
<tr>
<td>Observation says Negative</td>
<td>89</td>
<td>123</td>
</tr>
</table>

<br/>

<li> We can say that Naive-Bayes classifer performs well when compared to logistic-regression classifer and decision-tree beacuse of the following observations</li>
<li> The number of False positives for logistic-regression(42) and decision-tree(89) is more when compared to naive-bayes (38) which means to say that the Prediction 
is a "Positive" whereas according to the Observed data it is a "Negative" which is an error </li>
<li> The number of False negative for logistic-regression(37) and decision-tree(54) is more when compared to naive-bayes (36) which means to say that the Prediction 
is a "Negative" whereas according to the Observed data it is a "Positive" which is an error </li>



<hr/>

<h3 style="color:blue;">5. Plot training accuracy, 10-fold cross-validation accuracy 
and test accuracy together using matplotlib </h3>
<h3>Plot</h3>
<img src="graph.png" alt="Plot" style="width:600px;height:500px;">

<p> By observing the above plot, we can say that logistic-regression classifer overfits the most because it gives a high accuracy on the training data but the accuracy decreases
when tested using a data different from train data,on the other hand Naive-Bayes classifier performs well as it maintains consistency with all the data.</p>
<hr/>
<h3 style="color:blue;">6. Precision, recall, f1-score, confusion matrix (true positive, true negative, false positive, false negative)</h3>
<p style="color:blue;"><u>Confusion matrix</u></p>
<table border="1" style="width:300px">
<tr>
<td>Confusion Matrix</td>
<td>Prediction says Positive</td>
<td>Prediction says Negative</td>
</tr>
<tr>
<td>Observation says Positive</td>
<td>True positive</td>
<td>False negative</td>
</tr>
<tr>
<td>Observation says Negative</td>
<td>False positive</td>
<td>True negative</td>
</tr>
</table>

<p style="color:blue;"><u> Precision</u></p>
<p> Precision (also called positive predictive value) is the fraction of retrieved instances that are relevant.</p>
<p> Here, prediction is given by, true positives/(true positives + false positives)</p>
<p style="color:blue;"><u> Recall</u></p>
<p>Recall (also known as sensitivity) is the fraction of relevant instances that are retrieved</p>
<p> Here, Recall is given by, true positives/(true positives + false negatives)</p>
 <p style="color:blue;"><u> F1 score</u></p>
<p> F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results, and r is the number of correct positive results divided by the number
 of positive results that should have been returned. The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst at 0.</p>

<p>Here, F1 score is given by 2*Precision*Recall/(Precision+Recall)</p>

<hr/>

<h3 style="color:blue;">7. ROC curve and report the area under the curve</h2>
<p>
Receiver Operating Characteristic curve (or ROC curve) is a plot of the true positive rate 
against the false positive rate for the different possible threshold of a diagnostic test.</p>
<li>An ROC curve demonstrates several things:</li>
<li>1)It shows the tradeoff between sensitivity(Recall) and specificity (any increase in sensitivity will be accompanied by a decrease in specificity)
where Sensitivity= true positives/(true positive + false negative) and Specificity=true negatives/(true negative + false positives)</li>
<li>2)The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.</li>
<li>3)The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.</li>
<li>4)The slope of the tangent line at a cutpoint gives the likelihood ratio (LR) for that value of the test.</li>
<li>5)The area under the curve is a measure of text accuracy</li>

<p>Naive-Bayes Area under ROC: 0.7937542683305395</p>
<p>Logistic-Regression Area under ROC: 0.7797075805550382</p>
<p>Decision-tree Area under ROC: 0.6064208702348864</p>

<p> By observing the Area under ROC for all the three classifiers, we can determine that Naive_Bayes_classifier is more accurate</p>
<p style="color:blue;"><u> ROC Curve using logistic-regression</u></p>
<img src="ROC_LOR.png" alt="ROC Plot" style="width:400px;height:400px;">
<p>By the above graph, we can determine that the test is more accurate as the curve follows the left-hand border and then the top border of the ROC space</p>
<p>Since there are no methods to extract True Positive rates and False Positive rates for different threshold using naive-bayes model,the ROC plot for Naive-Bayes is not plotted</p>


<hr/>

<h3 style="color:blue;">8. Top 20 most informative features for all three classifiers</h3>
<p> We tried our level best to find the feature probabilities by using the tweet probabilities, but since only LR provides a way to find the probabilities, the program 
became complex and we were not able predict feature words correctly. We also know that term frequencies does not mean informative features and hence that implementation was not considered.</p>
<hr/>
<h3 style="color:blue;">9. Best classifier</h3>
<p> Naive-Bayes classifier is the best classifier.The Naive Bayes model assumes each feature to be independent of all other features.Thus, for example, if you had a feature "best"
and another "world's best", then their probabilities would be multiplied as though independent, even though the two are overlapping.By observing the graph(section 5) above we see that
 logistic-regression overfits the most.An overfit model is one that is too complicated 
for your data set. When this happens, the regression model becomes tailored to fit the quirks and random noise in the training data rather than reflecting the test data. If we test using a data 
different from training data, 
it would have its own quirks, and the original overfit model would not likely fit the new data.
The sample size limits the number of terms that you can safely include before you begin to overfit the model.Larger sample sizes allow you to specify more complex models.
For trustworthy results,the sample size must be large enough to support the level of complexity that is required by the 
question. If the sample size isn’t large enough, we won’t be able to fit a model that adequately approximates the true model for your response variable.</p>
<p>Cross-validation is a method by which we can detect if model overfits by determining how well the model performs to a different data set which was not there in the training data by partitioning the data
 observations.By observing the plot for 10-fold-cross-validation and test accuracy, it is evident that Naive-Bayes classifier performs better than Logistic-Regression and decision-tree.Hence,F1 score
which can be interpreted as a weighted average of the precision and recall is the highest for naive-bayes classifer.</p>
<hr/>
<p>

<h3 style="color:blue;">10. Sample tweets and their prediction probabilities</h3>
<p style="color:blue;"><u>Some 20 correctly classified tweets</u></p>
<li>1.4713582481465765e-05 "F*ck Time Warner Cable!!! You f*cking suck balls!!! I have a $700 HD tv &amp; my damn HD channels hardly ever come in. Bullshit!!"</li>
<li>0.00011270974515146502 "I hate Time Warner! Soooo wish I had Vios. Cant watch the fricken Mets game w/o buffering. I feel like im watching free internet porn."</li>
<li>0.00016248813230073473 "is being fucked by time warner cable. didnt know modems could explode. and Susan Boyle sucks too!"</li>
<li>0.00020327942685522717 "i srsly hate the stupid twitter API timeout thing, soooo annoying!!!!! :("</li>
<li>0.00021157264747809868 "@springsingfiend @dvyers @sethdaggett @jlshack AT&amp;T dropped the ball and isn't supporting crap with the new iPhone 3.0... FAIL #att SUCKS!!!"</li>
<li>0.00029058007594554307 "You guys see this?  Why does Time Warner have to suck so much ass?  Really wish I could get U-Verse at my apartment. http://bit.ly/s594j"</li>
<li>0.00030099904265909976 "RT @sportsguy33 The upside to Time Warner: unhelpful phone operators   superslow on-site service. Crap, that's not an upside."</li>
<li>0.00034777656547196716 "OMG - time warner f'ed up my internet install - instead of today  its now NEXT saturday - another week w/o internet! &amp;$*ehfa^V9fhg[*# fml."</li>
<li>0.0003709619961368655 "NOOOOOOO my DVR just died and I was only half way through the EA presser. Hate you Time Warner"</li>
<li>0.0003733819080695576 "i hate comcast right now. everything is down cable internet &amp; phone....ughh what am i to do"</li>
<li>0.00039571885606151083 "THE DENTIST LIED! "" U WON'T FEEL ANY DISCOMORT! PROB WON'T EVEN NEED PAIN PILLS"" MAN U TWIPPIN THIS SHIT HURT!! HOW MANY PILLS CAN I TAKE!!"</li>
<li>0.0006035941086036316 "@Mbjthegreat i really dont want AT&amp;T phone service..they suck when it comes to having a signal"</li>
<li>0.0006773395978129893 "argghhhh why won't  my jquery appear in safari bad safari !!!"</li>
<li>0.0010068600096215861 "Time Warner cable phone reps r dumber than nails!!!!! UGH! Cable was working 10 mins ago now its not WTF!"</li>
<li>0.0010254026526196232 "Safari 4 is fast :) Even on my shitty AT&amp;T tethering."</li>
<li>0.0010307444962566862 "@ Safeway. Place is a nightmare right now. Bumming."</li>
<li>0.0012333878078318406 "time warner really picks the worst time to not work. all i want to do is get to mtv.com so i can watch the hills. wtfffff."</li>
<li>0.00181996172248295 "Trouble in Iran, I see. Hmm. Iran. Iran so far away. #flockofseagullsweregeopoliticallycorrect"</li>
<li>0.0018791267462519514 "Took the Graduate Field Exam for Computer Science today.  Nothing makes you feel like more of an idiot than lambda calculus."</li>
<li>0.0019966424715237977 "#wolfram Alpha SUCKS! Even for researchers the information provided is less than you can get from #google or #wikipedia, totally useless!"</li>
<p style="color:blue;"><u>Top 5 correctly classified tweets</u></p>
<li>0.9999067671530703 "getting ready to test out some burger receipes this weekend. Bobby Flay has some great receipes to try. Thanks Bobby."</li>
<li>0.9998474558953657 "@cwong08 I have a Kindle2 (&amp; Sony PRS-500). Like it! Physical device feels good. Font is nice. Pg turns are snappy enuf. UI a little klunky."</li>
<li>0.9998150229368572 "Obama is quite a good comedian! check out his dinner speech on CNN :) very funny jokes."</li>
<li>0.9995385833125675 "@sklososky Thanks so much!!! ...from one of your *very* happy Kindle2 winners ; ) I was so surprised, fabulous. Thank you! Best, Kathleen"</li>
<li>0.9995194175671434 "@SoChi2 I current use the Nikon D90 and love it, but not as much as the Canon 40D/50D. I chose the D90 for the  video feature. My mistake."</li>
<p style="color:blue;"><u>Some 20 incorrectly classified tweets</u></p>
<li>0.014057071283084931 "My dad was in NY for a day, we ate at MESA grill last night and met Bobby Flay. So much fun, except I completely lost my voice today."</li>
<li>0.021490333357937937 "We went to Stanford University today. Got a tour. Made me want to go back to college. It's also decided all of our kids will go there."</li>
<li>0.034591424863606786 "SOOO DISSAPOiNTED THEY SENT DANNY GOKEY HOME... YOU STiLL ROCK ...DANNY ... MY HOMETOWN HERO !! YEAH MiLROCKEE!!"</li>
<li>0.0387172835343328 "@ atebits I just finished watching your Stanford iPhone Class session. I really appreciate it. You Rock!"</li>
<li>0.03885040572376286 "The great Indian tamasha truly will unfold from May 16, the result day for Indian General Election."</li>
<li>0.06438926834013219 "Malcolm Gladwell might be my new man crush"</li>
<li>0.07942954006769984 "Learning about lambda calculus :)"</li>
<li>0.08164125974253493 "is studing math ;) tomorrow exam and dentist :)"</li>
<li>0.09511942196152474 "Safeway is very rock n roll tonight"</li>
<li>0.10661809060889499 "Prettiest insects EVER - Pink Katydids: http://bit.ly/2Upw2p"</li>
<li>0.1520327085925114 "RT @shrop: Awesome JQuery reference book for Coda! http://www.macpeeps.com/coda/ #webdesign"</li>
<li>0.16286273594175527 "@dannygokey I love you DANNY GOKEY!! :)"</li>
<li>0.17358409639085454 "My wrist still hurts. I have to get it looked at. I HATE the dr/dentist/scary places. :( Time to watch Eagle eye. If you want to join, txt!"</li>
<li>0.17763906284669526 "omgg i ohhdee want mcdonalds damn i wonder if its open lol =]"</li>
<li>0.20217137971581703 "Class... The 50d is supposed to come today :)"</li>
<li>0.22977129066954602 "yankees won mets lost. its a good day."</li>
<li>0.23568256726433875 "zomg!!! I have a G2!!!!!!!"</li>
<li>0.25614066981033995 "#GoogleIO | O3D - Bringing 3d graphics to the browser. Very nice tbh. Funfun."</li>
<li>0.26092515992841103 "I seriously underestimated Malcolm Gladwell.  I want to meet this dude."</li>
<li>0.29473990505147707 "@matthewcyan I finally got around to using jquery to make my bio collapse. Yay for slide animations."</li>
<p style="color:blue;"><u>Top 5 incorrectly classified tweets</u></p>
<li>0.9991633208906028 "Cox or Time Warner?  Cox is cheaper and gets a B on dslreports.  TW is more expensive and gets a C."</li>
<li>0.9979965271278043 "I still love my Kindle2 but reading The New York Times on it does not feel natural. I miss the Bloomingdale ads."</li>
<li>0.9932202600197496 "Back from seeing 'Star Trek' and 'Night at the Museum.' 'Star Trek' was amazing, but 'Night at the Museum' was; eh."</li>
<li>0.9899347007270659 "I just created my first LaTeX file from scratch. That didn't work out very well. (See @amandabittner , it's a great time waster)"</li>
<li>0.9887543535683618 "looks like summize has gone down. too many tweets from WWDC perhaps?"</li>





<h2>References</h2>
<li>Wikipedia:<a href="http://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a></li>
<li>Apache Spark:<a href="http://spark.apache.org/docs/latest/mllib-guide.html">Spark Machine Learning library(MLlib) Guide</a></li>
<li>NLTK:<a href="http://www.nltk.org/api/nltk.stem.html">NLTK Porterstemmer</a></li>
<li>Matplotlib examples:<a href="http://matplotlib.org/users/pyplot_tutorial.html">pyplot tutorial</a></li>
<li><a href="http://blog.minitab.com/blog/adventures-in-statistics/the-danger-of-overfitting-regression-models">Overfitting Models</a></li>
<li><a href="http://gim.unmc.edu/dxtests/roc2.htm">How to Interpret ROC</a></li> 
<li> Discussed with Raghavendra Bableshwar,Viswas Reddy Kuruvalli,Vivek R. Shivaprabhu, Vishalaxi for program logic</li> 










    <!-- JS and analytics only. -->
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="//code.jquery.com/jquery.js"></script>
<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/datascience/js/bootstrap.min.js"></script>

  </body>
</html>


